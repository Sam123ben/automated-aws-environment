---
- hosts: localhost
  connection: local
  gather_facts: False
  vars_files:
    - "../configs/config.yml"

  tasks:

      - set_fact:
          vpc_id: "{{ project.name }}-{{ platform }}"

      - set_fact:
          route_name: "{{ vpc_id }}"

      - name: getting epoch time from shell
        command: "date +%s"
        register: epoch_time

      - name: set the current Epoch time fact
        set_fact:
          epoch_time: "{{ epoch_time.stdout }}"

      - name: Ansible check if the the ssh config file exist
        stat:
          path: '~/.ssh/config'
        register: check_config_file

      - name: Ansible check if the the ansible config file exist
        stat:
          path: '~/.ssh/ansible.cfg'
        register: check_ansible_config_file

      - block:

        - name: Have a backup of the current config file in case if present
          copy:
            src: '~/.ssh/ansible.cfg'
            dest: '~/.ssh/ansible_config_backup_{{ epoch_time }}'

        - name: Remove the existing config file
          shell: rm -rf ~/.ssh/ansible.cfg

        when: check_ansible_config_file.stat.exists

      - name: Copy the config file to the ssh dir to avoid host check
        copy:
          src: '../configs/ansible.cfg'
          dest: '~/.ssh/ansible.cfg'

      - name: Export the ansible config file
        shell: export ANSIBLE_CONFIG="~/.ssh/ansible.cfg"

      - block:

        - name: Have a backup of the current config file in case if present
          copy:
            src: '~/.ssh/config'
            dest: '~/.ssh/config_backup_{{ epoch_time }}'

        - name: Remove the existing config file
          shell: rm -rf ~/.ssh/config

        when: check_config_file.stat.exists

      - name: Copy the config file to the ssh dir to avoid host check
        copy:
          src: '../configs/config'
          dest: '~/.ssh/config'
        mode: 0400

      - name: Copy the policy template
        copy:
          src: './templates/iam_policy.json'
          dest: '/tmp/iam_policy.json'

      - name: Create an instance profile role for the ec2 to continue the kops installtion
        shell: aws iam create-role --role-name ec2AdminRole-{{ epoch_time }} --assume-role-policy-document file:///tmp/iam_policy.json
        register: instance_role

      - name: Attach the aws policy to the ec2 instance role and create the iam policy accordingly
        shell: "{{ item }}"
        with_items:
          - aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/AdministratorAccess --role-name ec2AdminRole-{{ epoch_time }}
          - aws iam create-instance-profile --instance-profile-name newEc2InstanceProfile-{{ epoch_time }}
          - aws iam add-role-to-instance-profile --role-name ec2AdminRole-{{ epoch_time }} --instance-profile-name newEc2InstanceProfile-{{ epoch_time }}

      - debug:
          msg: "{{ instance_role.stdout }}"

      - set_fact:
          instance_profile_role: "{{ instance_role.stdout }}"

      - name: create the custom VPC for the resources (Networking)
        ec2_vpc_net:
          name: "{{ vpc_id }}"
          cidr_block: "{{ cidr_block }}"
          region: "{{ region }}"
          state: present
    
      - name: Gather the vpc facts to proceed
        import_tasks: get-vpc-facts.yml

      - name: associate subnet to the VPC
        ec2_vpc_subnet:
          state: present
          vpc_id: "{{ vpc.id }}"
          region: "{{ region }}"
          cidr: "{{ subnet_cidr }}"
          map_public: yes
          resource_tags:
            Name: "{{ subnet_name }}"
        register: subnet
  
      - name: create the IGW
        ec2_vpc_igw:
          vpc_id: "{{ vpc.id }}"
          region: "{{ region }}"
          state: "present"
          tags:
            Name: "{{ igw_name }}"
        register: igw

      - name: Route the IGW in order to provide the access (Networking)
        ec2_vpc_route_table:
          vpc_id: "{{ vpc.id }}"
          region: "{{ region }}"
          subnets:
            - "{{ subnet.subnet.id }}"
          routes:
            - dest: 0.0.0.0/0
              gateway_id: "{{ igw.gateway_id  }}"
          tags:
            Name: "{{ route_name }}"
      
      # update the CIDR address in the SSH port section.
      
      - name: Create Security Group
        ec2_group:
          name: Web DMZ
          description: DMZ Security Group
          vpc_id: "{{ vpc.id }}"
          region: "{{ region }}"
          rules:
            - proto: tcp
              ports:
              - 80
              cidr_ip: 0.0.0.0/0
            - proto: tcp
              ports:
              - 22
              cidr_ip: 0.0.0.0/0
        register: security_group

      - set_fact:
          bucket_name: "poc-bucket-{{ vpc_id }}"

      - name: Create a policy document to be used acros by other resources to be able to download
        template:
          src: "admin_policy.json.j2"
          dest: "/tmp/admin_policy.json"

      # Create a simple s3 bucket
      - s3_bucket:
          name: '{{ bucket_name }}'
          policy: "{{ lookup('file','/tmp/admin_policy.json') }}"

      - name: Delete the cluster contents from the bucket if present
        shell: aws s3 rm s3://{{ bucket_name }} --recursive

      - name: create a new ec2 key pair to be used for accessing the new ec2 instances
        ec2_key:
          name: ec2_keypair
          region: "{{ region }}"
        register: keypair
      
      - name: Copy EC2 Private Key locally so it can be later on used to SSH into the instance
        copy: content="{{ keypair.key.private_key }}" dest={{ ec2_key_directory }}/ec2_keypair.pem
        when: keypair.changed == true

      - name: Chmod 0400 for the ssh keys
        shell: "chmod 0400 {{ ec2_key_directory }}/ec2_keypair.pem"

      - name: Gather the ami details dynamically
        import_tasks: get-ec2-ami.yml

      - name: Create the EC2 instance
        ec2:
          image: "{{ ec2_ami }}"
          wait: yes
          instance_type: t2.micro
          region: "{{ region }}"
          group_id: "{{ security_group.group_id }}"
          vpc_subnet_id: "{{ subnet.subnet.id }}"
          key_name: "{{ keypair.key.name  }}"
          count_tag:
            Name: "{{ vpc_id }}-webserver"
          exact_count: 1
          instance_tags:
            Name: "{{ vpc_id }}-webserver"

      - name: EC2 provision | Wait for EC2 SSH servers finish the initialization
        pause: seconds=120 prompt="Waiting for the EC2 SSH servers initialization"

      - Name: "Get the public dns name of the newly created ec2 instance"
        shell: aws ec2 describe-instances --region {{ region }} --filters "Name=tag:Name,Values={{ vpc_id }}-webserver" --output text --query 'Reservations[*].Instances[*].[PublicDnsName,Tags[?Key==`Application`].Value]'
        register: ec2_fact_dns

      - Name: "Get the instance id of the newly created ec2 instance"
        shell: aws ec2 describe-instances --region {{ region }} --filters "Name=tag:Name,Values={{ vpc_id }}-webserver" --output text --query 'Reservations[*].Instances[*].[InstanceId,Tags[?Key==`Application`].Value]'
        register: ec2_fact_id

      - set_fact:
          ec2_dns_name: "{{ ec2_fact_dns.stdout }}"

      - debug:
          msg: "{{ ec2_dns_name }}"

      - name: Write ec2 dynamic inventory file
        template:
          src: "inventory.j2"
          dest: "/tmp/inventory"

      - name: Attach the iam profile to the newly created instance
        shell: aws ec2 associate-iam-instance-profile --region {{ region }} --instance-id {{ ec2_fact_id.stdout }} --iam-instance-profile Name=newEc2InstanceProfile-{{ epoch_time }}
        ignore_errors: true

      - name: Backup the configure for the aws to be used later
        copy:
          src: '{{ item.src }}'
          dest: '{{ item.dest }}'
        with_items:
          - { src: ~/.aws/credentials, dest: /tmp/aws_credentials }